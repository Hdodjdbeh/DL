{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9870573,"sourceType":"datasetVersion","datasetId":6059129},{"sourceId":162830,"sourceType":"modelInstanceVersion","modelInstanceId":138465,"modelId":161121}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/core.py/transformers/default/1\")\nprint(sys.path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:43:53.151060Z","iopub.execute_input":"2024-11-11T21:43:53.151355Z","iopub.status.idle":"2024-11-11T21:43:53.163557Z","shell.execute_reply.started":"2024-11-11T21:43:53.151322Z","shell.execute_reply":"2024-11-11T21:43:53.162545Z"}},"outputs":[{"name":"stdout","text":"['/kaggle/lib/kagglegym', '/kaggle/lib', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/root/.local/lib/python3.10/site-packages', '/opt/conda/lib/python3.10/site-packages', '/root/src/BigQuery_Helper', '/kaggle/input/core.py/transformers/default/1']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from core import CharacterTokenizer\n","metadata":{"id":"5HmwpqzwnMyE","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:43:53.174474Z","iopub.execute_input":"2024-11-11T21:43:53.174818Z","iopub.status.idle":"2024-11-11T21:43:57.366074Z","shell.execute_reply.started":"2024-11-11T21:43:53.174784Z","shell.execute_reply":"2024-11-11T21:43:57.364979Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install transformers\n","metadata":{"id":"hkVexA2nnRQ5","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:01:16.760223Z","iopub.execute_input":"2024-11-11T21:01:16.760654Z","iopub.status.idle":"2024-11-11T21:01:48.871815Z","shell.execute_reply.started":"2024-11-11T21:01:16.760620Z","shell.execute_reply":"2024-11-11T21:01:48.870649Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import string\n\nimport sys\nchars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n\nmodel_max_length = 64\n\ntokenizer = CharacterTokenizer(chars, model_max_length)","metadata":{"id":"5FaCG9ajnS_G","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:43:58.020923Z","iopub.execute_input":"2024-11-11T21:43:58.021431Z","iopub.status.idle":"2024-11-11T21:43:58.031103Z","shell.execute_reply.started":"2024-11-11T21:43:58.021392Z","shell.execute_reply":"2024-11-11T21:43:58.030010Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")\n    \ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:43:58.561050Z","iopub.execute_input":"2024-11-11T21:43:58.561420Z","iopub.status.idle":"2024-11-11T21:43:58.598442Z","shell.execute_reply.started":"2024-11-11T21:43:58.561384Z","shell.execute_reply":"2024-11-11T21:43:58.597444Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"example = \"Привет\"\n\ntokens = tokenizer(example)\n\nprint(tokens)","metadata":{"id":"I5FSPMOSncpI","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:01.428125Z","iopub.execute_input":"2024-11-11T21:44:01.428504Z","iopub.status.idle":"2024-11-11T21:44:01.434008Z","shell.execute_reply.started":"2024-11-11T21:44:01.428469Z","shell.execute_reply":"2024-11-11T21:44:01.433100Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Задание: обучите модель классификации букв для задачи расстановки ударения с помощью методов из библиотеки transformers. Датасет для обучения можно взять отсюда: https://github.com/Koziev/NLP_Datasets/blob/master/Stress/all_accents.zip\n\n\n\n1. Напишите класс для Dataset/Dataloder и разбейте данные на случайные train / test сплиты в соотношении 50:50. (1 балл)\n\n2. Попробуйте обучить одну или несколько из моделей: Bert, Albert, Deberta. Посчитайте метрику Accuracy на train и test. (1 балл). При преодолении порога в Accuracy на test 0.8: (+1 балл), 0.85: (+2 балла), 0.89: (+3 балла).\n\nПример конфигурации для deberta: https://huggingface.co/IlyaGusev/ru-word-stress-transformer/blob/main/config.json","metadata":{"id":"KQkp36rEoScR"}},{"cell_type":"code","source":"import string\nimport sys\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:02.383949Z","iopub.execute_input":"2024-11-11T21:44:02.384328Z","iopub.status.idle":"2024-11-11T21:44:03.335382Z","shell.execute_reply.started":"2024-11-11T21:44:02.384290Z","shell.execute_reply":"2024-11-11T21:44:03.334166Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df = pd.read_table('/kaggle/input/dataset/all_accents.tsv', header=None, names = ['word', 'stressed_word'])\ndf['stress_idx'] = df['stressed_word'].str.find('^')\n\ntrain_df, test_df = train_test_split(df, test_size=0.5)","metadata":{"id":"mRVK6TNAZQFk","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:03.336861Z","iopub.execute_input":"2024-11-11T21:44:03.337333Z","iopub.status.idle":"2024-11-11T21:44:08.847744Z","shell.execute_reply.started":"2024-11-11T21:44:03.337294Z","shell.execute_reply":"2024-11-11T21:44:08.846751Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:08.849500Z","iopub.execute_input":"2024-11-11T21:44:08.850002Z","iopub.status.idle":"2024-11-11T21:44:08.863846Z","shell.execute_reply.started":"2024-11-11T21:44:08.849967Z","shell.execute_reply":"2024-11-11T21:44:08.862967Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                word  stressed_word  stress_idx\n52265    асессорский   ас^ессорский           2\n523782    каноничная    канон^ичная           5\n674701       михалко       мих^алко           3\n246748  вышивальщицы  вышив^альщицы           5\n605501  кюхельбекеры  кюхельб^екеры           7","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>stressed_word</th>\n      <th>stress_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>52265</th>\n      <td>асессорский</td>\n      <td>ас^ессорский</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>523782</th>\n      <td>каноничная</td>\n      <td>канон^ичная</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>674701</th>\n      <td>михалко</td>\n      <td>мих^алко</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>246748</th>\n      <td>вышивальщицы</td>\n      <td>вышив^альщицы</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>605501</th>\n      <td>кюхельбекеры</td>\n      <td>кюхельб^екеры</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"class WordStressDataset(Dataset):\n    def __init__(self, df, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.tokenizer = CharacterTokenizer(chars, model_max_length)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        word = self.df['word'].iloc[idx]\n        stress_idx = self.df['stress_idx'].iloc[idx]\n\n        tokens = self.tokenizer(\n            word,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        labels = torch.zeros((self.max_len), dtype=torch.long)\n        if stress_idx > 0:\n            labels[stress_idx] = 1\n        \n        return tokens['input_ids'].flatten(), tokens['attention_mask'].flatten(), labels\n\n\ntrain_dataset = WordStressDataset(train_df, model_max_length)\ntest_dataset = WordStressDataset(test_df, model_max_length)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:08.865017Z","iopub.execute_input":"2024-11-11T21:44:08.865600Z","iopub.status.idle":"2024-11-11T21:44:08.882619Z","shell.execute_reply.started":"2024-11-11T21:44:08.865557Z","shell.execute_reply":"2024-11-11T21:44:08.881631Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import DebertaV2ForTokenClassification, DebertaV2Config,  AdamW\n\nconfig = DebertaV2Config(\n    architectures=\"DebertaV2ForTokenClassification\",\n    model_type=\"deberta-v2\",\n    \n    vocab_size=len(tokenizer.get_vocab()),  # Размер словаря (включая специальные токены)\n    torch_dtype=\"float32\",\n    \n    hidden_size=768,  # Размер скрытого слоя\n    num_hidden_layers=4,  # Количество скрытых слоёв\n    num_attention_heads=12,  # Количество голов внимания\n    \n    intermediate_size=1024,  # Размер промежуточного слоя\n    hidden_act=\"gelu\",  # Функция активации для скрытых слоёв\n    hidden_dropout_prob=0.1,  # Вероятность dropout для скрытых слоёв\n    attention_probs_dropout_prob=0.1,  # Вероятность dropout для вероятностей внимания\n    max_position_embeddings=model_max_length,  # Максимальная длина последовательности\n    #type_vocab_size=1,  # Количество типов токенов (для сегментации)\n    #initializer_range=0.02,  # Диапазон инициализации весов\n    #layer_norm_eps=1e-7,  # Точность нормализации слоёв\n    #pad_token_id=0,  # ID токена для заполнения\n    #position_embedding_type=\"absolute\",  # Тип позиционного вложения\n    #use_cache=True,  # Использовать кеш для ускорения вычислений\n    \n    num_labels=2,  # Количество классов для задачи классификации (0 - без ударения, 1 - с ударением)\n)\n\nconfig = DebertaV2Config(\n    architectures=\"DebertaV2ForTokenClassification\",\n    model_type=\"deberta-v2\",\n    transformers_version=\"4.25.1\",\n    torch_dtype=\"float32\",\n    \n    num_labels=2,\n\n    hidden_size=1024,\n    intermediate_size=2048,\n    num_attention_heads=16,\n    num_hidden_layers=5,\n    \n    hidden_dropout_prob=0.2,\n    attention_probs_dropout_prob=0.2,\n    position_biased_input=True,\n    \n    vocab_size=len(tokenizer.get_vocab()),\n    \n    max_length=model_max_length,\n    max_position_embeddings=model_max_length,\n    max_relative_positions=model_max_length,\n    \n    output_attentions=False,\n    output_hidden_states=False,    \n    \n    #initializer_range=0.02,\n    pooler_dropout = 0,\n    pooler_hidden_act = \"gelu\",\n    pooler_hidden_size = 1536\n)\n\nmodel = DebertaV2ForTokenClassification(config)\noptimizer = torch.optim.AdamW(model.parameters(),lr = 1e-5,eps = 1e-8)\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:08.884647Z","iopub.execute_input":"2024-11-11T21:44:08.885228Z","iopub.status.idle":"2024-11-11T21:44:11.473065Z","shell.execute_reply.started":"2024-11-11T21:44:08.885185Z","shell.execute_reply":"2024-11-11T21:44:11.472260Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import AlbertConfig, AlbertForTokenClassification\n\nconfig = AlbertConfig(\n    num_labels=2,\n    hidden_size=600,\n    intermediate_size=800,\n    num_attention_heads=8,\n    num_hidden_layers=4,\n    hidden_dropout_prob=0.15,\n    attention_probs_dropout_prob=0.15,\n    max_position_embeddings=model_max_length,\n    vocab_size=len(tokenizer.get_vocab()),\n    output_attentions=False,\n    output_hidden_states=False,\n    pooler_dropout=0,\n    pooler_hidden_act=\"gelu\",\n    pooler_hidden_size=736\n)\n\nmodel = AlbertForTokenClassification(config).to(device)\noptimizer = torch.optim.AdamW(model.parameters(),lr = 1e-5,eps = 1e-8)\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:02:03.775058Z","iopub.execute_input":"2024-11-11T21:02:03.775549Z","iopub.status.idle":"2024-11-11T21:02:03.997989Z","shell.execute_reply.started":"2024-11-11T21:02:03.775513Z","shell.execute_reply":"2024-11-11T21:02:03.997045Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\ndef accuracy(preds, labels):    \n    return np.all(preds == labels, axis=1).sum() / len(labels)\n\ndef train(train_dataloader,epoch_i):\n    total_train_loss = 0\n    total_train_acc=0\n    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch_i}\")\n    for step, batch in enumerate(pbar):\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.to(device)\n        model.zero_grad()\n        outputs = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels)\n        loss = outputs.loss\n        total_train_loss += loss.item()\n        logits = torch.argmax(outputs.logits.detach(), dim=2).cpu().numpy()\n        label_ids = b_labels.cpu().numpy()\n        total_train_acc += accuracy_score(logits, label_ids)\n        loss.backward()\n        optimizer.step()\n    \n    avg_train_loss = total_train_loss / len(train_dataloader)\n    train_acc = total_train_acc/len(train_dataloader)\n    print(\"epoch:\", epoch_i)\n    print(\"Average training loss: \",avg_train_loss)\n    print(\"Train Accuracy: \", train_acc)\n    return avg_train_loss, train_acc\n\n\ndef validate(val_dataloader):\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n\n    pbar = tqdm(val_dataloader, desc=f\"Epoch {epoch_i}\")\n    for batch in pbar:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.to(device)\n        with torch.no_grad():\n            outputs = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels)\n        loss = outputs.loss\n        total_eval_loss += loss.item()\n        logits = torch.argmax(outputs.logits.detach(), dim=2).cpu().numpy()\n        label_ids = b_labels.cpu().numpy()\n        total_eval_accuracy += accuracy_score(logits, label_ids)\n\n    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n    print(\"Validation Accuracy: \",avg_val_accuracy)\n    avg_val_loss = total_eval_loss / len(val_dataloader)\n    print(\"Validation Loss: \",avg_val_loss)\n    \n    return avg_val_loss, avg_val_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:13.229396Z","iopub.execute_input":"2024-11-11T21:44:13.230433Z","iopub.status.idle":"2024-11-11T21:44:13.245076Z","shell.execute_reply.started":"2024-11-11T21:44:13.230391Z","shell.execute_reply":"2024-11-11T21:44:13.244082Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"for epoch_i in range(0, 10):\n    model.train()\n    avg_train_loss = train(train_dataloader,epoch_i)\n    \n    \n    model.eval()\n    avg_test_loss, avg_test_accuracy = validate(test_dataloader)\n    \nprint(\"test_loss\",avg_test_loss)\nprint(\"test_accuracy\",avg_test_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T12:54:45.869098Z","iopub.execute_input":"2024-11-11T12:54:45.869967Z","iopub.status.idle":"2024-11-11T16:15:22.139744Z","shell.execute_reply.started":"2024-11-11T12:54:45.869923Z","shell.execute_reply":"2024-11-11T16:15:22.138856Z"}},"outputs":[{"name":"stderr","text":"Epoch 0: 100%|██████████| 13130/13130 [12:01<00:00, 18.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 0\nAverage training loss:  0.024921558978375096\nTrain Accuracy:  0.4794677785086201\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|██████████| 13130/13130 [08:02<00:00, 27.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.6856705382076669\nValidation Loss:  0.017714026797937352\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 13130/13130 [12:00<00:00, 18.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 1\nAverage training loss:  0.01781186328992327\nTrain Accuracy:  0.6600008438343834\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 13130/13130 [08:01<00:00, 27.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.7336312357197258\nValidation Loss:  0.01528982267341231\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 13130/13130 [12:00<00:00, 18.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 2\nAverage training loss:  0.015929096718641497\nTrain Accuracy:  0.7005711027833552\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 13130/13130 [07:59<00:00, 27.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.7577022245493781\nValidation Loss:  0.013822882878505437\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 13130/13130 [12:03<00:00, 18.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 3\nAverage training loss:  0.014690429563524154\nTrain Accuracy:  0.7271236498649865\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 13130/13130 [07:58<00:00, 27.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.7816026434374207\nValidation Loss:  0.012683846273651716\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 13130/13130 [12:00<00:00, 18.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 4\nAverage training loss:  0.013713677077265478\nTrain Accuracy:  0.7484010420272796\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 13130/13130 [07:59<00:00, 27.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.7957801789794364\nValidation Loss:  0.011940560733150444\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 13130/13130 [12:01<00:00, 18.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 5\nAverage training loss:  0.012944675289251915\nTrain Accuracy:  0.7638584651734404\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 13130/13130 [08:07<00:00, 26.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8122417650418888\nValidation Loss:  0.011069575133460368\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 13130/13130 [12:05<00:00, 18.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 6\nAverage training loss:  0.012267993303634345\nTrain Accuracy:  0.7774264565879665\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 13130/13130 [07:59<00:00, 27.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.824631092916984\nValidation Loss:  0.010485043885170001\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 13130/13130 [12:00<00:00, 18.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 7\nAverage training loss:  0.011675494398300373\nTrain Accuracy:  0.7891171328671328\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 13130/13130 [07:58<00:00, 27.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8339858625285606\nValidation Loss:  0.009930044526403795\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 13130/13130 [12:00<00:00, 18.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 8\nAverage training loss:  0.011132831765680666\nTrain Accuracy:  0.8000180667105171\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 13130/13130 [08:08<00:00, 26.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8433160383346028\nValidation Loss:  0.009454715866822486\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 13130/13130 [12:00<00:00, 18.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 9\nAverage training loss:  0.010659029457245735\nTrain Accuracy:  0.808812335560479\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 13130/13130 [08:03<00:00, 27.18it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8513308422188374\nValidation Loss:  0.009011224937846533\ntest_loss 0.009011224937846533\ntest_accuracy 0.8513308422188374\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":76},{"cell_type":"markdown","source":"## Не хватило немного эпох до 0.89+ accuracy","metadata":{}},{"cell_type":"code","source":"for epoch_i in range(0, 4):\n    model.train()\n    avg_train_loss = train(train_dataloader,epoch_i)\n    \n    \n    model.eval()\n    avg_test_loss, avg_test_accuracy = validate(test_dataloader)\n    \nprint(\"test_loss\",avg_test_loss)\nprint(\"test_accuracy\",avg_test_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T16:16:06.880950Z","iopub.execute_input":"2024-11-11T16:16:06.881780Z","iopub.status.idle":"2024-11-11T17:38:41.770511Z","shell.execute_reply.started":"2024-11-11T16:16:06.881739Z","shell.execute_reply":"2024-11-11T17:38:41.769512Z"}},"outputs":[{"name":"stderr","text":"Epoch 0: 100%|██████████| 13130/13130 [12:01<00:00, 18.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 0\nAverage training loss:  0.01020920947640964\nTrain Accuracy:  0.8179043264903414\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|██████████| 13130/13130 [08:03<00:00, 27.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8581683168316832\nValidation Loss:  0.008526345587658971\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 13130/13130 [12:00<00:00, 18.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 1\nAverage training loss:  0.009811300349436695\nTrain Accuracy:  0.8245801383022917\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 13130/13130 [08:00<00:00, 27.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8656706175425235\nValidation Loss:  0.008164386950863805\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 13130/13130 [12:14<00:00, 17.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 2\nAverage training loss:  0.009438721328085006\nTrain Accuracy:  0.8321270468392993\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 13130/13130 [09:15<00:00, 23.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8710042999492258\nValidation Loss:  0.007873923504783262\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 13130/13130 [12:16<00:00, 17.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 3\nAverage training loss:  0.009073447128750741\nTrain Accuracy:  0.8387408692792356\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 13130/13130 [08:42<00:00, 25.13it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8744482260726073\nValidation Loss:  0.007584021631514786\ntest_loss 0.007584021631514786\ntest_accuracy 0.8744482260726073\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":77},{"cell_type":"markdown","source":"## Ну опять не вышло((","metadata":{}},{"cell_type":"markdown","source":"## Попробуем DEBERTA","metadata":{}},{"cell_type":"code","source":"from transformers import DebertaV2ForTokenClassification, DebertaV2Config,  AdamW\n\n\n\nconfig = DebertaV2Config(\n\n    architectures=\"DebertaV2ForTokenClassification\",\n\n    model_type=\"deberta-v2\",\n\n    vocab_size=len(tokenizer.get_vocab()),  # Размер словаря (включая специальные токены)\n\n    torch_dtype=\"float32\",\n\n\n    hidden_size=768,  # Размер скрытого слоя\n\n    num_hidden_layers=5,  # Количество скрытых слоёв\n\n    num_attention_heads=12,  # Количество голов внимания\n\n\n    intermediate_size=1024,  # Размер промежуточного слоя\n\n    hidden_act=\"gelu\",  # Функция активации для скрытых слоёв\n\n    hidden_dropout_prob=0.15,  # Вероятность dropout для скрытых слоёв\n\n    attention_probs_dropout_prob=0.15,  # Вероятность dropout для вероятностей внимания\n\n    max_position_embeddings=model_max_length,  # Максимальная длина последовательности\n\n    #type_vocab_size=1,  # Количество типов токенов (для сегментации)\n\n    #initializer_range=0.02,  # Диапазон инициализации весов\n\n    #layer_norm_eps=1e-7,  # Точность нормализации слоёв\n\n    #pad_token_id=0,  # ID токена для заполнения\n\n    #position_embedding_type=\"absolute\",  # Тип позиционного вложения\n\n    #use_cache=True,  # Использовать кеш для ускорения вычислений\n\n\n    num_labels=2,  # Количество классов для задачи классификации (0 - без ударения, 1 - с ударением)\n\n)\n\n\n\nmodel = DebertaV2ForTokenClassification(config)\n\noptimizer = torch.optim.AdamW(model.parameters(),lr = 1e-5,eps = 1e-8)\n\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:16.479679Z","iopub.execute_input":"2024-11-11T21:44:16.480505Z","iopub.status.idle":"2024-11-11T21:44:16.807515Z","shell.execute_reply.started":"2024-11-11T21:44:16.480464Z","shell.execute_reply":"2024-11-11T21:44:16.806535Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"for epoch_i in range(0, 8):\n    model.train()\n    avg_train_loss = train(train_dataloader,epoch_i)\n    \n    \n    model.eval()\n    avg_test_loss, avg_test_accuracy = validate(test_dataloader)\n    \nprint(\"test_loss\",avg_test_loss)\nprint(\"test_accuracy\",avg_test_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T21:44:18.363885Z","iopub.execute_input":"2024-11-11T21:44:18.364918Z","iopub.status.idle":"2024-11-12T02:01:55.440334Z","shell.execute_reply.started":"2024-11-11T21:44:18.364876Z","shell.execute_reply":"2024-11-12T02:01:55.439408Z"}},"outputs":[{"name":"stderr","text":"Epoch 0: 100%|██████████| 13130/13130 [21:19<00:00, 10.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 0\nAverage training loss:  0.020321631030820065\nTrain Accuracy:  0.6126946228276674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|██████████| 13130/13130 [10:53<00:00, 20.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.7536851040873318\nValidation Loss:  0.01450563134055979\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 13130/13130 [21:19<00:00, 10.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 1\nAverage training loss:  0.013932480558934597\nTrain Accuracy:  0.76119184033788\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 13130/13130 [10:52<00:00, 20.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.811151704112719\nValidation Loss:  0.011451647324652127\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 13130/13130 [21:18<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 2\nAverage training loss:  0.011705329339924323\nTrain Accuracy:  0.802114129682199\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 13130/13130 [10:51<00:00, 20.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8420324003554202\nValidation Loss:  0.009645751973164396\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 13130/13130 [21:18<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 3\nAverage training loss:  0.010219450263513617\nTrain Accuracy:  0.829266664647234\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 13130/13130 [10:57<00:00, 19.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8690360021579081\nValidation Loss:  0.008323738534146776\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 13130/13130 [21:18<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 4\nAverage training loss:  0.009120552733087286\nTrain Accuracy:  0.8487477714117566\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 13130/13130 [10:53<00:00, 20.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8828934215536939\nValidation Loss:  0.007416820818961223\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 13130/13130 [21:18<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 5\nAverage training loss:  0.008266201357020992\nTrain Accuracy:  0.8634048501003947\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 13130/13130 [10:53<00:00, 20.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.8940633726834223\nValidation Loss:  0.006790210511980498\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 13130/13130 [21:18<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 6\nAverage training loss:  0.007560571455863083\nTrain Accuracy:  0.8751680095894204\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 13130/13130 [10:53<00:00, 20.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.9016505616907845\nValidation Loss:  0.006171510118922157\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 13130/13130 [21:18<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 7\nAverage training loss:  0.006987494059096417\nTrain Accuracy:  0.8847129664889566\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 13130/13130 [10:52<00:00, 20.12it/s]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy:  0.9097788144199036\nValidation Loss:  0.005747463491972981\ntest_loss 0.005747463491972981\ntest_accuracy 0.9097788144199036\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}